{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f67c33",
   "metadata": {},
   "source": [
    "### <font color = \"red\">Inferential Statistics :-</font> \n",
    "While descriptive statistics focuses on summarizing and visualizing data, inferential statistics allows us to make predictions, draw conclusions, and generalize insights from a sample to an entire population.\n",
    "\n",
    "Imagine you are analyzing customer behavior for an e-commerce platform. It is impractical to collect data from every single customer (the population). Instead, you collect data from a smaller group of customers (a sample). But how can you confidently make statements about the entire population based on just this sample? This is where inferential statistics comes into play.\n",
    "\n",
    "Inferential statistics helps us:\n",
    "\n",
    "    Generalize insights from a sample to the population.\n",
    "\n",
    "    Test hypotheses to validate assumptions or claims about the data.\n",
    "\n",
    "    Quantify uncertainty by calculating confidence intervals and p-values.\n",
    "\n",
    "    Make predictions using statistical models.\n",
    "Covariance, correlation, regression, and hypothesis testing are all part of Inferential Statistics ‚Äî because they help us make conclusions or predictions about a population based on sample data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d97c59",
   "metadata": {},
   "source": [
    "### <font color = \"red\">Parameters:-</font>\n",
    "\n",
    "A population parameter is a numerical value that describes a characteristic of a whole population (not just a sample).\n",
    "\n",
    "It is a fixed value, but usually unknown (because we rarely study the full population).\n",
    "\n",
    "We estimate it using sample statistics (like sample mean, sample proportion, etc.).\n",
    "\n",
    "It's the target of inferential statistics.\n",
    "\n",
    "**üìä Common Population Parameters**\n",
    "\n",
    "| **Parameter**              | **Symbol**        | **Description**                            |\n",
    "|----------------------------|-------------------|--------------------------------------------|\n",
    "| Population Mean            | $\\mu$             | Average of all values in the population    |\n",
    "| Population Proportion      | $p$               | Proportion of population with a trait      |\n",
    "| Population Variance        | $\\sigma^2$        | Spread of data around the mean             |\n",
    "| Population Standard Deviation | $\\sigma$       | Square root of the variance                |\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9684b0",
   "metadata": {},
   "source": [
    "### <font color = \"red\">Point Estimate :- </font>\n",
    "\n",
    "A point estimate is a single value that best estimates a population parameter. Point estimation uses a random sample to estimate the population value(Parameter). For example, the sample mean estimates the population mean.\n",
    "\n",
    "Estimation is a key goal of inferential statistics. This branch of statistics uses random samples to estimate the properties of entire populations. Parameters are population properties, such as the population mean. Unfortunately, they are generally unknowable because measuring a whole population is difficult. However, sample statistics calculated from a random sample can estimate the population parameter.\n",
    "\n",
    "In inferential statistics, estimation methods generally fall into two main types: point estimates, which provide a single best guess, and interval estimates, which offer a range of plossible values. While other estimation approaches exist in more advanced settings, these two categories form the foundation of most statistical inference.\n",
    "\n",
    "**Properties of a Good Point Estimate:-**\n",
    "\n",
    "A good point estimate is consistent, unbiased, and efficient. All these terms have specific meanings in a statistical context. Let‚Äôs learn more about them!\n",
    "\n",
    "**Consistent Estimate:-**\n",
    "\n",
    "A consistent point estimate means that the estimate tends to get closer to the population parameter as the sample size increases. Imagine trying to estimate the average height of all adult women in a city. If you only measure 10 women, your estimate will be off by some amount. However, as you measure the heights of more and more women, a consistent estimator will converge on the correct population value. It tends to get closer and closer to the parameter with larger samples.\n",
    "\n",
    "**Unbaised Estimate:-**\n",
    "\n",
    "An unbiased estimator is a point estimate that is not consistently too high or too low compared to the population parameter. For example, if you take multiple random samples of adult women and measure their heights, the sample means won‚Äôt systematically overestimate or underestimate the population‚Äôs average height. Additionally, if you average multiple unbiased point estimates, the average tends to converge on the correct value.\n",
    "\n",
    "**Efficency:-**\n",
    "\n",
    "Efficiency in point estimates means getting the most accurate result possible with the least amount of data. Using the example of estimating the average height of all adults in a city, an efficient estimator makes the best use of the data you collect, providing an estimate with minimal variability.\n",
    "\n",
    "\n",
    "**In Previous Notes We Study about sampling Distribution of mean and Central Limit Theoram These are also Type of Point Estimation**\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1f30d",
   "metadata": {},
   "source": [
    "### <font color = \"red\"> Confidence Interval:-</font>\n",
    "\n",
    "A Confidence Interval (CI) is a range of values that is likely to contain the true value of something you're trying to measure, based on your sample.\n",
    "\n",
    "It doesn‚Äôt give you one fixed number but a range ‚Äî and tells you how confident you can be that the true answer lies inside that range.\n",
    "\n",
    "**Real-Life Explanation:-**\n",
    "Let‚Äôs say you're trying to guess how many runs Virat Kohli will score in his next match. You watch his past 50 innings and calculate some statistics.\n",
    "\n",
    "Now Instead of saying:\n",
    "\n",
    "    \"He will definitely score 56 runs\"\n",
    "\n",
    "...you can say something smarter like:\n",
    "\n",
    "    \"I am 95% confident that he will score between 46 and 66 runs\"\n",
    "That‚Äôs a Confidence Interval.\n",
    "\n",
    "**üéØ Key Terms**:-\n",
    "\n",
    "**Confidence Level (e.g., 95%):** This means that if we repeated the experiment 100 times, about 95 out of those 100 times, the true value would fall inside the calculated interval.\n",
    "\n",
    "Margin of Error: The plus/minus range around the estimate.\n",
    "\n",
    "**Example - Explained with and without Confidence Interval:-**\n",
    "\n",
    "Let‚Äôs use a different but similar example to make it more fun and useful.\n",
    "\n",
    "*Q: How many marks will Atul get in his next Statistics test?*\n",
    "\n",
    "‚úÖ Based on past 20 tests:\n",
    "    \n",
    "    Mean = 70\n",
    "\n",
    "    Standard Devation = 10\n",
    "Without Confidence Interval:\n",
    "\n",
    "    Atul will score 70 marks.(This is just a point estimate ‚Äî it's risky, doesn't tell us uncertainty.)\n",
    "\n",
    "With Confidence Interval:-\n",
    "### üìä Confidence Interval Example: Atul's Expected Marks\n",
    "\n",
    "| Confidence Level | Marks Range (Confidence Interval) | Interpretation                                               |\n",
    "|------------------|-----------------------------------|---------------------------------------------------------------|\n",
    "| 50%              | 65 to 75                          | There's a 50% chance Atul's marks will fall in this range.   |\n",
    "| 95%              | 60 to 80                          | We're 95% confident that Atul will score between 60‚Äì80 marks. |\n",
    "| 99%              | 55 to 85                          | We're 99% confident the score lies between 55‚Äì85 marks.       |\n",
    "\n",
    "\n",
    "**Confidence Interval Formula:-**\n",
    "$$CI=Point¬†Estimate¬±(Critical¬†Value√óStandard¬†Error)$$\n",
    "$$or$$\n",
    "$$CI=Point¬†Estimate¬±Margin¬†of¬†Error$$\n",
    "\n",
    "**There are two main ways (or methods) to calculate a Confidence Interval (CI) ‚Äî based on Z-procedure and T-procedure:-**\n",
    "\n",
    "‚úÖ 1. Z-Procedure (Z-Distribution):-\n",
    "\n",
    "    When to Use:\n",
    "\n",
    "        You know the population standard deviation (œÉ).\n",
    "        Sample size is large (n ‚â• 30) ‚Äî Central Limit Theorem applies.\n",
    "        The population is normally distributed, or the sample size is large enough.\n",
    "\n",
    "üîπ Formula:-\n",
    "\n",
    "$$\n",
    "CI = \\bar{x} \\pm Z^* \\cdot \\left( \\frac{\\sigma}{\\sqrt{n}} \\right)\n",
    "$$\n",
    "Where , <br>\n",
    "    $\\bar{x}:$ Sample Mean ‚Äî the average value from your sample.\n",
    "    <br>$Z^*:$ Z-critical value ‚Äî depends on your confidence level (e.g., 1.96 for 95% confidence).\n",
    "    <br>$\\sigma :$ Population standard deviation\n",
    "    <br>$n:$ Sample size ‚Äî number of observations in your sample.\n",
    "\n",
    "‚úÖ 2. T-Procedure (T-Distribution)\n",
    "\n",
    "    When to Use:\n",
    "        \n",
    "        You don‚Äôt know the population standard deviation (œÉ).\n",
    "        Sample size is small (n < 30).\n",
    "        Population is approximately normal or symmetric.\n",
    "\n",
    "üîπ Formula:-\n",
    "$$\n",
    "CI = \\bar{x} \\pm t^* \\cdot \\left( \\frac{s}{\\sqrt{n}} \\right)\n",
    "$$\n",
    "Where, <br>\n",
    "    $\\bar{x}:$ Sample Mean ‚Äî the average value from your sample.\n",
    "    <br>$t^*$: t-critical value ‚Äî depends on confidence level and degrees of freedom $(df = n - 1)$.\n",
    "    <br>$s$: Sample standard deviation ‚Äî used in T-procedure (when œÉ is unknown).\n",
    "    <br>$n:$ Sample size ‚Äî number of observations in your sample.\n",
    "\n",
    "---\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e73516",
   "metadata": {},
   "source": [
    "### <font Color = 'Red'>**‚úÖ 1. Z-Procedure (Z-Distribution/Sigma Known) in Detail:-**</font>\n",
    "\n",
    "---\n",
    "**Assumptions for Z-Procedure (When œÉ is Known)**\n",
    "\n",
    "To use the Z-procedure for calculating confidence intervals, the following assumptions must be met:\n",
    "\n",
    "1. **Known Population Standard Deviation (œÉ)**  \n",
    "   - The population standard deviation must be known.  \n",
    "   - This is often unrealistic in practice, but useful in theoretical or large-sample scenarios.\n",
    "\n",
    "2. **Random Sampling**  \n",
    "   - The sample should be randomly selected from the population.  \n",
    "   - This ensures that the sample represents the population well.\n",
    "\n",
    "3. **Independence**  \n",
    "   - Observations should be independent of each other.  \n",
    "   - This usually means the sample size should be <10% of the population (when sampling without replacement).\n",
    "\n",
    "4. **Normal Distribution OR Large Sample Size**  \n",
    "   - If the population is normally distributed, any sample size is fine.  \n",
    "   - If the population is not normal, then the sample size should be **large (n ‚â• 30)** due to the Central Limit Theorem (CLT).  \n",
    "   - CLT ensures the sampling distribution of the mean is approximately normal.\n",
    "\n",
    "---\n",
    "üîπ Formula:-\n",
    "\n",
    "$$\n",
    "CI = \\bar{x} \\pm Z^* \\cdot \\left( \\frac{\\sigma}{\\sqrt{n}} \\right)\n",
    "$$\n",
    "\n",
    "$Z^* = Z_\\frac{\\alpha}{2}$\n",
    "\n",
    "\n",
    "Where , <br>\n",
    "    $\\bar{x}:$ Sample Mean ‚Äî the average value from your sample.\n",
    "    <br>$Z^*:$ Z-critical value ‚Äî depends on your confidence level (e.g., 1.96 for 95% confidence).\n",
    "    <br>$\\sigma :$ Population standard deviation\n",
    "    <br>$n:$ Sample size ‚Äî number of observations in your sample.\n",
    "\n",
    "**Let's Breakdown Formula Step-By-Step**:-<br>\n",
    "<u>Step 1: Sampling Distribution of the Mean</u><br>\n",
    "&emsp;&emsp;&emsp;$Mean = \\mu$<br>\n",
    "&emsp;&emsp;&emsp;$Known\\;Standard\\;Devation = \\sigma$ <br>\n",
    "&emsp;&emsp;Then according to the Central Limit Theorem:<br>\n",
    "$$\\bar{X} \\sim \\mathcal{N}(\\mu, \\frac{\\sigma}{\\sqrt{n}})$$\n",
    "&emsp;&emsp;So The Sample Mean $\\bar{x}$ is Normally Distributed around the true mean $\\mu$ with Standard Devation $\\frac{\\sigma}{\\sqrt{n}}$<br>\n",
    "\n",
    "<u>Step 2: Standardizing the Sample Mean</u><br>\n",
    "&emsp;We want to Know how far our sample mean $\\bar{x}$ could be from the true mean $\\mu$.So , We Want Z-Score Formula: \n",
    "$$\n",
    "Z = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n",
    "$$\n",
    "&emsp;This Follow Standard Normal Distribution\n",
    "$$\n",
    "Z \\sim \\mathcal{N}(0, 1)\n",
    "$$\n",
    "\n",
    "<u>Step 3: Bring in Œ± (Alpha) and the Confidence Level</u><br>\n",
    "&emsp;Now we set a confidence level, say 95%. This means we allow 5% error, split in two tails of the normal curve:\n",
    "$$\n",
    "\\alpha = 1 - confidence Interval = 0.05\n",
    "$$\n",
    "&emsp;So Each tail has:\n",
    "$$\n",
    "\\frac{\\alpha}{2} = 0.025\n",
    "$$\n",
    "&emsp; If we set a confidence level , say 93%. This means we allow 7% error , split in two tails the normal curve: \n",
    "$$\n",
    "\\alpha = 0.07 \\rightarrow \\frac{\\alpha}{2} =0.035\n",
    "$$\n",
    "<p align=\"center\" style = 'background-color : White'>\n",
    "  <img src=\"images/R.png\" alt=\"Image\" width=\"500\"/>\n",
    "</p>\n",
    "<br><br>\n",
    "&emsp;Now we find Z-critical value :\n",
    "\n",
    "$$\n",
    "P(-Z^* < Z < Z^*) = 1 - \\alpha\n",
    "$$\n",
    "\n",
    "&emsp;For 95% of Confidence level it give:\n",
    "\n",
    "$$\n",
    "Z^* \\approx 1.96\n",
    "$$\n",
    "&emsp; How this 1.96 came in:(This is importan)<br>\n",
    "<p align=\"center\" style = 'background-color : White'>\n",
    "  <img src=\"images/z-score.png\" alt=\"Image\" width=\"700\" , height = 500/>\n",
    "</p>\n",
    "\n",
    "&emsp;$P(Z<Z^*) = 0.95+0.025 \\implies 0.975$<br>\n",
    "\n",
    "To find the Z-critical value for a 95% confidence level, we look at the Z-table and find the Z-score that leaves 2.5% in the right tail. This means we're looking for the value with 97.5% of the area to the left.\n",
    "\n",
    "&emsp;From the Z-table, the Z-score corresponding to 0.975 is approximately 1.96.\n",
    "\n",
    "&emsp;Because the normal distribution is symmetric, the confidence interval includes values from ‚Äì1.96 to +1.96.\n",
    "\n",
    "So, the Z-critical value is ¬±1.96 for a 95% confidence level.\n",
    "\n",
    "\n",
    "<u>Step 4: Rearranging the Z Formula:-</U><br>\n",
    "Step-by-Step Breakdown of Confidence Interval Formula (Z-Procedure, œÉ known)\n",
    "\n",
    "Start with the Z-score formula\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{x} - \\mu}{\\sigma / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "This formula tells you how many standard errors the sample mean $\\bar{x}$ is away from the true mean $\\mu$.\n",
    "\n",
    "\n",
    "Rearranging the formula to solve for $\\mu$\n",
    "\n",
    "Start with:\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{x} - \\mu}{\\sigma / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Now multiply both sides by $\\frac{\\sigma}{\\sqrt{n}}$:\n",
    "\n",
    "$$\n",
    "Z \\cdot \\frac{\\sigma}{\\sqrt{n}} = \\bar{x} - \\mu\n",
    "$$\n",
    "\n",
    "Now isolate $\\mu$ (move it to the left-hand side):\n",
    "\n",
    "$$\n",
    "\\mu = \\bar{x} - Z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\quad \\text{(Lower Bound)}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\mu = \\bar{x} + Z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\quad \\text{(Upper Bound)}\n",
    "$$\n",
    "\n",
    "\n",
    "So we get the confidence interval:\n",
    "\n",
    "$$\n",
    "\\bar{x} - Z^* \\cdot \\frac{\\sigma}{\\sqrt{n}} < \\mu < \\bar{x} + Z^* \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "\n",
    "Final Confidence Interval Formula\n",
    "\n",
    "$$\n",
    "CI = \\bar{x} \\pm Z^* \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "This is the Z-procedure confidence interval for estimating the population mean when $\\sigma$ is known.\n",
    "\n",
    "\n",
    "Meaning of Each Variable:\n",
    "\n",
    "| Symbol         | Meaning                                   |\n",
    "|----------------|--------------------------------------------|\n",
    "| $\\bar{x}$  | Sample mean                                |\n",
    "| $Z^*$      | Z-critical value (based on confidence level) |\n",
    "| $\\sigma$   | Population standard deviation              |\n",
    "| $n$        | Sample size                                |\n",
    "| $\\frac{\\sigma}{\\sqrt{n}}$ | Standard Error (spread of sample means) |\n",
    "\n",
    "---\n",
    "---\n",
    "<u>**‚úÖ Factors Affecting Margin of Error (ME)**</u>\n",
    "\n",
    "The margin of error in confidence interval estimation is:\n",
    "\n",
    "$$\n",
    "\\text{Margin of Error} = Z^* \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "| **Factor**                        | **Effect on Margin of Error**                   | **Why**                                                                 |\n",
    "|----------------------------------|--------------------------------------------------|-------------------------------------------------------------------------|\n",
    "| **Confidence Level ($1 - \\alpha$)** | ‚Üë Higher confidence ‚Üí ‚Üë Larger $Z^*$ ‚Üí ‚Üë ME      | More confidence needs a wider interval to \"capture\" the true mean      |\n",
    "| **Population Standard Deviation ($\\sigma$)** | ‚Üë Larger $\\sigma$ ‚Üí ‚Üë ME                        | More variability in data increases uncertainty                         |\n",
    "| **Sample Size ($n$)**            | ‚Üë Larger $n$ ‚Üí ‚Üì ME                             | Larger samples reduce standard error $\\left(\\frac{\\sigma}{\\sqrt{n}}\\right)$ |\n",
    "\n",
    "---\n",
    "---\n",
    "<u>**‚úÖ Interpretation of Confidence Level :-**</u>\n",
    "\n",
    "When we say:\n",
    "\n",
    "      \"We are 95% confident that the population mean lies between 45 and 55\"\n",
    "\n",
    "It does NOT mean there is a 95% probability that the true mean is in this interval for this sample.\n",
    "\n",
    "Instead, it means:\n",
    "\n",
    "      If we repeated this sampling method many times, then 95% of those confidence intervals would contain the true population mean.\n",
    "\n",
    "üí° In short:\n",
    "The confidence level tells you how confident you are in the method, not the particular interval.\n",
    "\n",
    "For example:\n",
    "\n",
    "      A 95% confidence level means \"In the long run, 95 out of 100 intervals we compute like this will capture the true parameter.\" \n",
    "\n",
    "\n",
    "**Below Some Link That Will Give you Visulization effect of diffrent parameter**:-\n",
    "\n",
    "<a herf=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa0VQUjRaMHdwMjlkeXhVVXBWUkRNU3E5MzZQQXxBQ3Jtc0trQU1BOVhUZ1prV2RHQXBqd3ZnTXFmQ1JEOFFvR0dLaklWTEhUcVJtMjBNN2VSRDRFWjctYm9yWUxhMVRKdmpuMU5BRmh4N0JaN0M2TjY4QU53Znd0eGs1bEZVTUI2NmdwSlMtTEhBY2lIVENTVU9vUQ&q=https%3A%2F%2Fcampusx-official-confidence-interval-viz-app-kwg6wq.streamlit.app%2F&v=X52HK2qkiIE\"> Link_1\n",
    "</a>\n",
    "\n",
    "<a herf=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqblBaaHFFbjVQRDZ0eXNVM2pRZjc5TjNKdVBGUXxBQ3Jtc0trSTJtMUNzR0drS012Y2ptN2NhTmx4bnpTTDNhMWJuTVRHc0lhcHNOdkdPNEcyQkM1bWV3WmF6MS1NeEwxSnQ3aDdRaGlLbXRZV0RESVFMTGdEQ3BiY0hUVDNkck1MckI5TFZzbDFKbmZvZ1VXaHI3RQ&q=https%3A%2F%2Fcampusx-official-z-distribution-conf-confidence-interval-bx6u60.streamlit.app%2F&v=X52HK2qkiIE\"> Link_2\n",
    "</a>\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8721c43",
   "metadata": {},
   "source": [
    "<font Color = 'Red'>**‚úÖ 1. T-Procedure (T-Distribution/Sigma Unknown) in Detail:-**</font>\n",
    "---\n",
    "\n",
    "**üîÅ Why Do We Use the T-Distribution Instead of Z?**\n",
    "\n",
    "When the population standard deviation (œÉ) is unknown, we estimate it using the sample standard deviation (s). This estimate introduces extra variability into the process. Hence, instead of using the standard normal (Z) distribution, we use the t-distribution, which adjusts for that extra uncertainty ‚Äî especially for small sample sizes (n < 30).\n",
    "\n",
    "**üìò Assumptions for Using the T-Procedure (œÉ Unknown):-**\n",
    "\n",
    "To apply the t-procedure correctly when constructing confidence intervals or performing hypothesis testing about a population mean, the following assumptions must be satisfied:\n",
    "\n",
    "1. Random Sampling:-\n",
    "\n",
    "&emsp; *-- The data must be collected using a random sampling method.*<br>\n",
    "&emsp; *-- This ensures the sample is representative of the population.*<br>\n",
    "&emsp; *-- It helps to minimize bias and allows the results to be generalized to the entire population.*<br>\n",
    "\n",
    "2. Population Standard Deviation (œÉ) is Unknown:-\n",
    "\n",
    "&emsp; *-- Since the true population standard deviation œÉ is not known, we use the sample standard deviation (s) as an estimate.*<br>\n",
    "&emsp; *-- The t-distribution accounts for the extra variability introduced by estimating œÉ using s.*<br>\n",
    "\n",
    "3. Approximately Normal Population Distribution:-\n",
    "\n",
    "&emsp; *-- The population should be approximately normally distributed, especially when the sample size is small (n < 30).*<br>\n",
    "&emsp; *-- If the sample size is large, the Central Limit Theorem (CLT) ensures the sampling distribution of the mean is<br>\n",
    "&emsp;&emsp;&emsp;approximately normal, even if the population is not.*<br>\n",
    "&emsp; *-- ‚ö†Ô∏è Caution: If the data is heavily skewed or has extreme outliers, the t-procedure may not be reliable. <br>\n",
    "&emsp;&emsp;&emsp;In such cases, consider using non-parametric methods.*<br>\n",
    "\n",
    "4. Independence of Observations:-\n",
    "\n",
    "&emsp; *-- Each observation in the sample must be independent of the others.*<br>\n",
    "&emsp; *-- That means the value of one observation should not influence or be related to another.*<br>\n",
    "&emsp; *-- This is especially important in cases like time series data, where values can be correlated.*<br>\n",
    "\n",
    "‚úÖ If all four assumptions are met, the t-procedure gives a reliable method for estimating population means and conducting inference when œÉ is unknown.\n",
    "\n",
    "---\n",
    "**What is T-Distribution ?**\n",
    "\n",
    "Student's t-distribution, also known as the t-distribution, is a probability distribution that is used in statistics for making inferences about the population mean when the sample size is small or when the population standard deviation is unknown. It is similar to the standard normal distribution (Z-distribution), but it has heavier tails. Theoretical work on t-distribution was done by W.S. Gosset; he has published his findings under the pen name \"Student\". That's why it is called a Student's t-test. The t-score represents the number of standard deviations the sample mean is away from the population mean.\n",
    "\n",
    "-- Looks similar to normal distribution, but with fatter tails\n",
    "\n",
    "-- Fatter tails = more spread, which compensates for the extra uncertainty\n",
    "\n",
    "-- As sample size increases, the t-distribution becomes more like Z (normal distribution)\n",
    "\n",
    "<font Color = 'Red'>*Note :- To Understand Uncertinty and Degree Of Freedom Goto last Markdown Cell and comback again and read it again*</font>\n",
    "\n",
    "---\n",
    "\n",
    "**üîπ Formula of T-Procedure To Get Confidence Level:-**\n",
    "$$\n",
    "CI = \\bar{x} \\pm t_{\\alpha/2, \\, df} \\cdot \\dfrac{s}{\\sqrt{n}}\n",
    "$$\n",
    "Where, <br>\n",
    "    $\\bar{x}$ ‚Üí Sample mean<br>\n",
    "    $t_{\\alpha/2, df}$ ‚Üí Critical value from the t-distribution for a given confidence level<br>\n",
    "    $\\alpha$ is the significance level (e.g., 0.05 for 95% CI)\n",
    "    $df = n - 1$ is the degrees of freedom (for one sample)<br>\n",
    "    $s$ ‚Üí Sample standard deviation<br>\n",
    "    $n$ ‚Üí Sample size<br>\n",
    "\n",
    "*How will Alpha Came in picture you now that from Z-procedure it is same and if you follow that you also familer with degree of freedom*\n",
    "\n",
    "**Now Exploring S (If we take more than one sample, shouldn't we have more than one $s$):-**\n",
    "\n",
    "if you draw many samples of size $n$ from the population, you'll end up with:<br>\n",
    "&emsp;&emsp;Sample 1: mean = $\\bar{x}_1$, std dev = $s_1$<br>\n",
    "&emsp;&emsp;Sample 2: mean = $\\bar{x}_2$, std dev = $s_2$<br>\n",
    "&emsp;&emsp;Sample 3: mean = $\\bar{x}_3$, std dev = $s_3$<br>\n",
    "&emsp;&emsp; ....<br>\n",
    "&emsp;&emsp;Sample k: mean = $\\bar{x}_k$, std dev = $s_k$</br>\n",
    "\n",
    "So each sample has its own $s$ (and $\\bar{x}$), because each sample will be a bit different due to randomness.\n",
    "\n",
    "If we had access to many samples, we could: Average the $s$ values of all sample .\n",
    "\n",
    "*To get value of &emsp; $t_{\\alpha/2, \\, df}$ &emsp;  use T-table.*\n",
    "\n",
    "**calculate the $t^*$ (t critical value) for a 95% confidence level:-**\n",
    "\n",
    "We need to calculate:\n",
    "$$\n",
    "t^*=t_{\\alpha/2, \\, df}\n",
    "$$\n",
    "\n",
    "‚ÄãThis depends on:\n",
    "\n",
    "&emsp;&emsp; 1. Confidence level: 95% ‚Üí so $\\alpha = 1 - 0.95 = 0.05$<br>\n",
    "&emsp;&emsp; 2. Degrees of freedom (df): depends on your sample size ‚Üí $df = n - 1$\n",
    "\n",
    "So I‚Äôll show you how to calculate $t^*$ for different common sample sizes.\n",
    "\n",
    "**Example:-**\n",
    "Let‚Äôs say your sample size $n = 15$<br>\n",
    "Then:<br>\n",
    "&emsp;&emsp;$df = 15 - 1 = 14$<br>\n",
    "&emsp;&emsp;For 95% confidence level ‚Üí $\\alpha = 0.05$, so look up $t_{0.025, 14}$ in a t-table<br>\n",
    "\n",
    "$t^* = 2.145$ --> Findout This value using T-table\n",
    "\n",
    "$t_{0.025}$ -- > is $\\frac{\\alpha}{2}$ value at confidence level of 95% and degree of freedom is 14, You can check it using confidence level and degree of freedom in t-table\n",
    "\n",
    "**Below Link give some Visulization about T-Distribution:-**\n",
    "\n",
    "<a herf=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbXdMM2ZFLVo2WnNCVGUtMUt3c2dLc2hHcU1pZ3xBQ3Jtc0trU0FNckE5Z2I1ZW1zUzB2ZS1iOWxtcUtiOF9mY082aG10cTNPWDItTkNwXzczZmRUTXQ1M0Zjam9DaTlUakI5SmdQcW5ZSm9Ib1k2cUVRX0E1MEhXQ05mUGdJdjIwTjdLcGtlY21lTmQzR2VlVmdxcw&q=https%3A%2F%2Fcampusx-official-normal-distribution-vs-t-distributi-app-28si1q.streamlit.app%2F&v=X52HK2qkiIE\"> Link_3\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754627f",
   "metadata": {},
   "source": [
    "<font color = \"red\" size =12>**Uncertinity:-**</font>\n",
    "\n",
    "In the real word, uncertainty (sometimes called error or bias) is a part of everyday life, but in statistics we try to quantify just how much uncertainty is in our experiment, survey or test results.\n",
    "\n",
    "The two main types are epistemic (things we don‚Äôt known because of a lack of data or experience) and aleatoric (things that are simply unknown, like what number a die will show on the next roll).\n",
    "\n",
    "<font color = \"red\" > **Sources of Uncertainty:-**</font>\n",
    "\n",
    "**Sampling Error:** This discrepancy arises between the value derived from a sample and the authentic value of the population parameter. Sampling error emerges because a sample merely approximates the complete population.\n",
    "\n",
    "**Measurement Error:** This discrepancy emerges between the measured value and the authentic value of a variable. Measurement error can emanate from inaccuracies in instruments, observer bias, or errors in data recording.\n",
    "\n",
    "**Natural Variability:** The innate variation in natural phenomena or systems, inducing uncertainty in statistical models and predictions.\n",
    "\n",
    "<font color = \"red\" >**Quantifying Uncertainty:-**</font>\n",
    "\n",
    "**Confidence Intervals:** This range of values encompasses the authentic population parameter, accompanied by a specified level of confidence (a 95% confidence interval, for instance).\n",
    "\n",
    "**Standard Errors:** This measure of estimate variability often finds application in constructing confidence intervals or conducting hypothesis tests.\n",
    "\n",
    "**Probability Distributions:** A function representing the likelihood of distinct potential outcomes for a random variable, assisting in quantifying uncertainty and making predictions.\n",
    "\n",
    "\n",
    "\n",
    "**Confidence Level vs Uncertainty**\n",
    "\n",
    "|Confidence Level |\tUncertainty|\n",
    "|-----------------|------------|\n",
    "| 90%             |\t10%        |\n",
    "| 95%\t          | 5%         |\n",
    "| 99%             | 1%         |\n",
    "\n",
    "**Standard Error (SE)**\n",
    "\n",
    "**Standard Error** is the standard deviation of a statistic (like the mean) from sample to sample.  \n",
    "It measures the variability of the sample mean from one sample to another.\n",
    "\n",
    "If you're estimating a population mean $ \\mu $ from a sample mean $ \\bar{x} $:\n",
    "\n",
    "$$\n",
    "\\text{Standard Error} = \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\sigma $ = population standard deviation (or sample standard deviation if population SD is unknown)  \n",
    "- $ n $ = sample size  \n",
    "\n",
    "‚úÖ **Why it's important**: Smaller Standard Error ‚Üí Less uncertainty in your estimate of the population mean.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660bc972",
   "metadata": {},
   "source": [
    "<font color = \"red\" Size = 12>**Degrees of Freedom:-**</font>\n",
    "\n",
    "The degrees of freedom (DF) in statistics indicate the number of independent values that can vary in an analysis without breaking any constraints. It is an essential idea that appears in many contexts throughout statistics including hypothesis tests, probability distributions, and linear regression.\n",
    "\n",
    "Degrees of freedom are the number of independent values that a statistical analysis can estimate. You can also think of it as the number of values that are free to vary as you estimate parameters. I know, it‚Äôs starting to sound a bit murky!\n",
    "\n",
    "DF encompasses the notion that the amount of independent information you have limits the number of parameters that you can estimate. Typically, the degrees of freedom equals your sample size minus the number of parameters you need to calculate during an analysis. It is usually a positive whole number.\n",
    "\n",
    "Degrees of freedom is a combination of how much data you have and how many parameters you need to estimate. It indicates how much independent information goes into a parameter estimate. In this vein, it‚Äôs easy to see that you want a lot of information to go into parameter estimates to obtain more precise estimates and more powerful hypothesis tests. So, you want many DF!\n",
    "\n",
    "<Font color = \"red\">**Independent Information and Constraints on Values**</Font>\n",
    "\n",
    "The degrees of freedom definitions talk about independent information. You might think this refers to the sample size, but it‚Äôs a little more complicated than that. To understand why, we need to talk about the freedom to vary. The best way to illustrate this concept is with an example.\n",
    "\n",
    "Suppose we collect the random sample of observations shown below. Now, imagine we know the mean, but we don‚Äôt know the value of an observation‚Äîthe X in the table below.\n",
    "\n",
    "![alt text](images\\DF_mean.webp)\n",
    "\n",
    "The mean is 6.9, and it is based on 10 values. So, we know that the values must sum to 69 based on the equation for the mean.\n",
    "\n",
    "Using simple algebra (64 + X = 69), we know that X must equal 5.\n",
    "\n",
    "As you can see, that last number has no freedom to vary. It is not an independent piece of information because it cannot be any other value. Estimating the parameter, the mean in this case, imposes a constraint on the freedom to vary. The last value and the mean are entirely dependent on each other. Consequently, after estimating the mean, we have only 9 independent pieces of information, even though our sample size is 10.\n",
    "\n",
    "That‚Äôs the basic idea for DF in statistics. In a general sense, DF are the number of observations in a sample that are free to vary while estimating statistical parameters. You can also think of it as the amount of independent data that you can use to estimate a parameter.\n",
    "\n",
    "The degrees of freedom formula is straightforward. Calculating the degrees of freedom is often the sample size minus the number of parameters you‚Äôre estimating:\n",
    "\n",
    "DF = N ‚Äì P\n",
    "\n",
    "Where:\n",
    "\n",
    "N = sample size\n",
    "P = the number of parameters or relationships\n",
    "\n",
    "For example, the degrees of freedom formula for a 1-sample t test equals N ‚Äì 1 because you‚Äôre estimating one parameter, the mean. To calculate degrees of freedom for a 2-sample t-test, use N ‚Äì 2 because there are now two parameters to estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3badd03",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
