{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c20e49b5",
   "metadata": {},
   "source": [
    "<font color = \"red\"  size = 12> **Regression Metrics** </font>\n",
    "\n",
    "**1. Introduction**\n",
    "Regression metrics help evaluate how well a predictive model approximates the actual values. Three commonly used metrics are:\n",
    "- **Mean Absolute Error (MAE)**\n",
    "- **Mean Squared Error (MSE)**\n",
    "- **Root Mean Squared Error (RMSE)**\n",
    "\n",
    "Each of these metrics gives different insights into model performance, error magnitudes, and the presence of outliers.\n",
    "\n",
    "\n",
    "### **2. Mean Absolute Error (MAE)**\n",
    "#### **Formula:**\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "Where:\n",
    "- $ y_i $ = Actual value\n",
    "- $ \\hat{y}_i $ = Predicted value\n",
    "- $ n $ = Number of observations\n",
    "\n",
    "**Intuition:**\n",
    "- Measures the average absolute differences between predicted and actual values.\n",
    "- **Advantage**: Simple and interpretable.(Give Result on Same scale like if we pridict i mean unit of matrix and data are same)\n",
    "- **Disadvantage**: Doesn't square errors, so it doesn't highlight large deviations.\n",
    "\n",
    "![alt text](images\\1_jTznOE9Gq6QVrGJ5eVQI4A.png)\n",
    "\n",
    "**3. Mean Squared Error (MSE)**\n",
    "**Formula:**\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "**Intuition:**\n",
    "- MSE penalizes larger errors more than smaller ones since it squares the residuals.\n",
    "- **Advantage**: Helps in differentiating models with larger errors.\n",
    "- **Disadvantage**: Sensitive to outliers due to squaring.(Not get Result on same scale)\n",
    "\n",
    "![alt text](images\\mean-squared-error.png)\n",
    "\n",
    "**4. Root Mean Squared Error (RMSE)**\n",
    "**Formula:**\n",
    "$$\n",
    "RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "**Intuition:**\n",
    "- RMSE converts the squared error back to the original units, making interpretation easier.\n",
    "- **Advantage**: Balances sensitivity to outliers while retaining interpretability.\n",
    "- **Disadvantage**: Still affected by large residuals more than MAE.\n",
    "\n",
    "\n",
    "\n",
    "**5. Comparison & Choosing the Right Metric**\n",
    "| **Metric** | **Sensitivity to Outliers** | **Interpretability** | **Use Case** |\n",
    "|------------|----------------------------|----------------------|--------------|\n",
    "| **MAE** | Low | Easy to interpret | General error measurement |\n",
    "| **MSE** | High | Less interpretable | Penalizes large errors more |\n",
    "| **RMSE** | Medium | Interpretable | When outlier effects need to be managed |\n",
    "\n",
    "\n",
    "**Summary**\n",
    "- **MAE**: Measures average absolute error. Best for simpler models.\n",
    "- **MSE**: Penalizes large deviations, useful when avoiding big errors.\n",
    "- **RMSE**: Provides a balance between interpretability and penalizing larger errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef48014",
   "metadata": {},
   "source": [
    "<font color = \"Red\">**$R^2 - SCORE$**</font>\n",
    "\n",
    "\n",
    "**üéØ Goal of R¬≤**\n",
    "\n",
    "R¬≤ measures how **well the regression model explains the variability** of the output (target) variable.\n",
    "\n",
    "> **In simple terms:**  \n",
    "> R¬≤ tells us **how much of the variation in Y is explained by X**.\n",
    "\n",
    "\n",
    "\n",
    "**üß± Step-by-Step Intuition + Formulas**\n",
    "\n",
    "**‚úÖ Step 1: Visualize the Problem**\n",
    "\n",
    "Imagine you're trying to predict sales (`y`) based on marketing budget (`x`).  \n",
    "You plot the data points and fit a line using **Linear Regression**.\n",
    "\n",
    "![alt text](images\\Coefficient_of_Determination.svg.png)\n",
    "\n",
    "‚¨ÜÔ∏è The curved black line is the mean of y\n",
    "\n",
    "‚¨ÜÔ∏è The blue line is your regression model\n",
    "\n",
    "‚¨ÜÔ∏è Points are actual values\n",
    "\n",
    "\n",
    "**‚ú≥Ô∏è Components of Variation**\n",
    "\n",
    "There are 3 important terms:\n",
    "\n",
    "| Name                              | Formula                            | Meaning                           |\n",
    "| --------------------------------- | ---------------------------------- | --------------------------------- |\n",
    "| **SST** (Total Sum of Squares)    | $\\sum (y_i - \\bar{y})^2$           | Total variation in y              |\n",
    "| **SSR** (Residual Sum of Squares) | $\\sum (y_i - \\hat{y}_i)^2$         | Error left by the model           |\n",
    "| **SSM** (Model Sum of Squares)    | $\\sum (\\hat{y}_i - \\bar{y})^2$     | Variation explained by the model  |\n",
    "\n",
    "Where:\n",
    "- $y_i$ = actual value  \n",
    "- $\\hat{y}_i$ = predicted value  \n",
    "- $\\bar{y}$ = mean of actual y values\n",
    "\n",
    "\n",
    "\n",
    "**üìê Graphical Meaning of Each**\n",
    "\n",
    "- **SST** = total vertical distance from each point to the **mean line**  \n",
    "- **SSR** = vertical distance from each point to the **regression line**  \n",
    "- **SSM** = distance from regression line to mean line\n",
    "\n",
    "**Relationship:**\n",
    "\n",
    "$$\n",
    "\\text{SST} = \\text{SSR} + \\text{SSM}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**üìè R¬≤ Formula**\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\text{SSM}}{\\text{SST}} = 1 - \\frac{\\text{SSR}}{\\text{SST}}\n",
    "$$\n",
    "\n",
    "- Perfect model ‚Üí SSR = 0 ‚Üí $R^2 = 1$  \n",
    "- Model as good as mean ‚Üí SSR = SST ‚Üí $R^2 = 0$  \n",
    "- Model worse than mean ‚Üí SSR > SST ‚Üí $R^2 < 0$\n",
    "\n",
    "\n",
    "\n",
    "**üí° Interpretation**\n",
    "\n",
    "| R¬≤ Value | Meaning                                       |\n",
    "| -------- | --------------------------------------------- |\n",
    "| 1        | Perfect model ‚Äî explains 100% of the variance |\n",
    "| 0.9      | Explains 90% of the variation in Y            |\n",
    "| 0.5      | Explains 50% ‚Äî the other 50% is noise         |\n",
    "| 0        | Model no better than mean                     |\n",
    "| < 0      | Model worse than mean (rare!)                 |\n",
    "\n",
    "\n",
    "\n",
    "**üìä Example Calculation**\n",
    "\n",
    "Suppose we have:\n",
    "\n",
    "| x | y (actual) | ≈∑ (predicted) |\n",
    "| - | ---------- | ------------- |\n",
    "| 1 | 2          | 2.2           |\n",
    "| 2 | 3          | 2.8           |\n",
    "| 3 | 5          | 5.1           |\n",
    "| 4 | 4          | 4.2           |\n",
    "| 5 | 6          | 5.9           |\n",
    "\n",
    "**Step 1: Mean of y**\n",
    "\n",
    "$$\n",
    "\\bar{y} = \\frac{2 + 3 + 5 + 4 + 6}{5} = 4\n",
    "$$\n",
    "\n",
    "**Step 2: SST (Total variation)**\n",
    "\n",
    "$$\n",
    "(2-4)^2 + (3-4)^2 + (5-4)^2 + (4-4)^2 + (6-4)^2 = 4 + 1 + 1 + 0 + 4 = 10\n",
    "$$\n",
    "\n",
    "**Step 3: SSR (Residual error)**\n",
    "\n",
    "$$\n",
    "(2-2.2)^2 + (3-2.8)^2 + (5-5.1)^2 + (4-4.2)^2 + (6-5.9)^2 = 0.04 + 0.04 + 0.01 + 0.04 + 0.01 = 0.14\n",
    "$$\n",
    "\n",
    "**Step 4: R¬≤**\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{0.14}{10} = 1 - 0.014 = 0.986\n",
    "$$\n",
    "\n",
    "‚úÖ **98.6% of the variation in y is explained by the model**\n",
    "\n",
    "\n",
    "\n",
    "**‚ö†Ô∏è When R¬≤ Can Be Misleading**\n",
    "\n",
    "- A high R¬≤ doesn't guarantee a good model.\n",
    "    - Model could be **overfitting**\n",
    "    - **Outliers** can inflate R¬≤\n",
    "    - It doesn‚Äôt work well for **non-linear relationships**\n",
    "- Always plot residuals and consider **Adjusted R¬≤** in multiple regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121a6bf",
   "metadata": {},
   "source": [
    "<font color = \"Red\">**Adjusted $R^2 - SCORE$**</font>\n",
    "\n",
    "\n",
    "**üö© Why Adjusted R¬≤ Came Into Picture**\n",
    "\n",
    "Let‚Äôs say you're building a regression model and keep adding more features (predictor variables):\n",
    "\n",
    "| Model | Features Used                               | R¬≤ Score |\n",
    "| ----- | ------------------------------------------- | -------- |\n",
    "| A     | `TV Spend`                                  | 0.78     |\n",
    "| B     | `TV + Radio`                                | 0.84     |\n",
    "| C     | `TV + Radio + Mag`                          | 0.88     |\n",
    "| D     | `TV + Radio + Mag + Weather + Day + Region` | 0.91     |\n",
    "\n",
    "üí° **You‚Äôll notice:**\n",
    "\n",
    "> As we keep adding features, R¬≤ **always increases** or stays the same.\n",
    "\n",
    "> Even if the new feature is **completely useless**, R¬≤ might still go up a little ‚Äî **that‚Äôs a problem**!\n",
    "\n",
    "\n",
    "\n",
    "**‚ö†Ô∏è Problem with R¬≤**\n",
    "\n",
    "R¬≤ rewards complexity.\n",
    "\n",
    "But more variables = more chance of **overfitting** ‚Äî fitting to noise rather than true patterns.\n",
    "\n",
    "\n",
    "\n",
    "**‚úÖ Adjusted R¬≤ to the Rescue!**\n",
    "\n",
    "Adjusted R¬≤ **penalizes unnecessary variables**.\n",
    "\n",
    "It answers:\n",
    "\n",
    "> ‚ÄúIs this new variable really helping the model? Or just making it complex without any real gain?‚Äù\n",
    "\n",
    "**üí° Intuition**\n",
    "\n",
    "| Metric          | Tells You                                                                  |\n",
    "| --------------- | -------------------------------------------------------------------------- |\n",
    "| **R¬≤**          | How much variance your model explains                                      |\n",
    "| **Adjusted R¬≤** | How much *useful* variance is explained, adjusted for number of predictors |\n",
    "\n",
    "So, **Adjusted R¬≤ increases only if the new feature actually helps**.\n",
    "If not, it can **decrease**, unlike R¬≤ which never goes down.\n",
    "\n",
    "\n",
    "\n",
    "**üìê Adjusted R¬≤ Formula**\n",
    "\n",
    "Let:\n",
    "\n",
    "* `n` = number of data points\n",
    "* `k` = number of independent variables (features)\n",
    "* `R¬≤` = regular R¬≤\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - \\left(1 - R^2\\right) \\cdot \\frac{n - 1}{n - k - 1}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**üëÄ What does this formula do?**\n",
    "\n",
    "* It multiplies the unexplained part `(1 - R¬≤)` with a **correction factor**:\n",
    "\n",
    "$$\n",
    "\\frac{n - 1}{n - k - 1}\n",
    "$$\n",
    "\n",
    "* More variables (higher `k`) ‚Üí higher penalty\n",
    "* Less data (lower `n`) ‚Üí higher penalty\n",
    "\n",
    "\n",
    "**üß™ Numerical Example**\n",
    "\n",
    "Suppose:\n",
    "\n",
    "* `n = 30` observations\n",
    "* Model A has `k = 2` features\n",
    "* R¬≤ = 0.90\n",
    "\n",
    "Now compute **Adjusted R¬≤**:\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - (1 - 0.9) \\cdot \\frac{29}{27} = 1 - 0.1 \\cdot 1.074 = 0.8926\n",
    "$$\n",
    "\n",
    "\n",
    "**Now suppose you add a **useless feature**:**\n",
    "\n",
    "* `k = 3`, and R¬≤ becomes 0.905\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - (1 - 0.905) \\cdot \\frac{29}{26} = 1 - 0.095 \\cdot 1.115 = 0.894\n",
    "$$\n",
    "\n",
    "‚úÖ So Adjusted R¬≤ **barely improved** ‚Üí small gain.\n",
    "\n",
    "If the new feature was noise, Adjusted R¬≤ would go **down**!\n",
    "\n",
    "\n",
    "\n",
    "**üìâ What If New Feature Is Useless?**\n",
    "\n",
    "Suppose R¬≤ increases just slightly:\n",
    "R¬≤ = 0.902\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - (1 - 0.902) \\cdot \\frac{29}{26} = 1 - 0.098 \\cdot 1.115 = 0.891\n",
    "$$\n",
    "\n",
    "üòü It actually **went down** from 0.8926 ‚Üí 0.891\n",
    "üëâ This feature made your model *worse*, even though R¬≤ increased.\n",
    "\n",
    "\n",
    "\n",
    "**üîç Use Case in Real Life**\n",
    "\n",
    "When you‚Äôre comparing **multiple regression models** with different numbers of features:\n",
    "\n",
    "| Model       | Features Used                      | R¬≤   | Adjusted R¬≤ |\n",
    "| ----------- | ---------------------------------- | ---- | ----------- |\n",
    "| Basic       | `TV`                               | 0.76 | 0.755       |\n",
    "| Improved    | `TV + Radio`                       | 0.84 | 0.832       |\n",
    "| Too Complex | `TV + Radio + Region + Day + Temp` | 0.87 | 0.843 ‚úÖ     |\n",
    "\n",
    "The third model looks good in R¬≤ but Adjusted R¬≤ tells you it‚Äôs **barely better than 2-feature model**.\n",
    "\n",
    "\n",
    "**üìä Graphical Intuition**\n",
    "\n",
    "If you want to picture it like a curve:\n",
    "\n",
    "* R¬≤ will keep increasing or flatten\n",
    "* Adjusted R¬≤ increases then **starts to decrease** when features are just noise\n",
    "\n",
    "```\n",
    "Adjusted R¬≤\n",
    "   ‚ñ≤\n",
    "1  |          ____\n",
    "   |         /\n",
    "   |   _____/\n",
    "   |\n",
    "   +--------------------‚ñ∂ Number of Features\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**üß† Summary Table**\n",
    "\n",
    "| Term        | Meaning                                                  |\n",
    "| ----------- | -------------------------------------------------------- |\n",
    "| R¬≤          | Total variance explained by model                        |\n",
    "| Adjusted R¬≤ | True explanatory power **adjusted for model complexity** |\n",
    "| Penalty     | Based on number of features & sample size                |\n",
    "| Use Case    | Best for comparing **multiple regression** models        |\n",
    "\n",
    "\n",
    "\n",
    "**‚úÖ When to Use Adjusted R¬≤**\n",
    "\n",
    "| Scenario                                 | Use Adjusted R¬≤? |\n",
    "| ---------------------------------------- | ---------------- |\n",
    "| Simple Linear Regression (1 variable)    | ‚ùå Not needed     |\n",
    "| Multiple Linear Regression               | ‚úÖ YES            |\n",
    "| Comparing models with different features | ‚úÖ YES            |\n",
    "| Feature selection during model tuning    | ‚úÖ YES            |\n",
    "\n",
    "\n",
    "\n",
    "**üë®‚Äçüè´ Final Advice**\n",
    "\n",
    "* R¬≤ is useful, but don‚Äôt trust it blindly\n",
    "* When building models with more than 1 feature, **always check Adjusted R¬≤**\n",
    "* It acts like a **truth detector** ‚Äî filtering out \"fake gains\" in R¬≤\n",
    "* Pair Adjusted R¬≤ with **Cross-validation**, **RMSE**, and **MAE** for serious modeling\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
