{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c20e49b5",
   "metadata": {},
   "source": [
    "<font color = \"red\"  size = 12> **Regression Metrics** </font>\n",
    "\n",
    "**1. Introduction**\n",
    "Regression metrics help evaluate how well a predictive model approximates the actual values. Three commonly used metrics are:\n",
    "- **Mean Absolute Error (MAE)**\n",
    "- **Mean Squared Error (MSE)**\n",
    "- **Root Mean Squared Error (RMSE)**\n",
    "\n",
    "Each of these metrics gives different insights into model performance, error magnitudes, and the presence of outliers.\n",
    "\n",
    "\n",
    "### **2. Mean Absolute Error (MAE)**\n",
    "#### **Formula:**\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "Where:\n",
    "- $ y_i $ = Actual value\n",
    "- $ \\hat{y}_i $ = Predicted value\n",
    "- $ n $ = Number of observations\n",
    "\n",
    "**Intuition:**\n",
    "- Measures the average absolute differences between predicted and actual values.\n",
    "- **Advantage**: Simple and interpretable.(Give Result on Same scale like if we pridict i mean unit of matrix and data are same)\n",
    "- **Disadvantage**: Doesn't square errors, so it doesn't highlight large deviations.\n",
    "\n",
    "![alt text](images\\1_jTznOE9Gq6QVrGJ5eVQI4A.png)\n",
    "\n",
    "**3. Mean Squared Error (MSE)**\n",
    "**Formula:**\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "**Intuition:**\n",
    "- MSE penalizes larger errors more than smaller ones since it squares the residuals.\n",
    "- **Advantage**: Helps in differentiating models with larger errors.\n",
    "- **Disadvantage**: Sensitive to outliers due to squaring.(Not get Result on same scale)\n",
    "\n",
    "![alt text](images\\mean-squared-error.png)\n",
    "\n",
    "**4. Root Mean Squared Error (RMSE)**\n",
    "**Formula:**\n",
    "$$\n",
    "RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "**Intuition:**\n",
    "- RMSE converts the squared error back to the original units, making interpretation easier.\n",
    "- **Advantage**: Balances sensitivity to outliers while retaining interpretability.\n",
    "- **Disadvantage**: Still affected by large residuals more than MAE.\n",
    "\n",
    "\n",
    "\n",
    "**5. Comparison & Choosing the Right Metric**\n",
    "| **Metric** | **Sensitivity to Outliers** | **Interpretability** | **Use Case** |\n",
    "|------------|----------------------------|----------------------|--------------|\n",
    "| **MAE** | Low | Easy to interpret | General error measurement |\n",
    "| **MSE** | High | Less interpretable | Penalizes large errors more |\n",
    "| **RMSE** | Medium | Interpretable | When outlier effects need to be managed |\n",
    "\n",
    "\n",
    "**Summary**\n",
    "- **MAE**: Measures average absolute error. Best for simpler models.\n",
    "- **MSE**: Penalizes large deviations, useful when avoiding big errors.\n",
    "- **RMSE**: Provides a balance between interpretability and penalizing larger errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef48014",
   "metadata": {},
   "source": [
    "<font color = \"Red\">**$R^2 - SCORE$**</font>\n",
    "\n",
    "\n",
    "**ğŸ¯ Goal of RÂ²**\n",
    "\n",
    "RÂ² measures how **well the regression model explains the variability** of the output (target) variable.\n",
    "\n",
    "> **In simple terms:**  \n",
    "> RÂ² tells us **how much of the variation in Y is explained by X**.\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ§± Step-by-Step Intuition + Formulas**\n",
    "\n",
    "**âœ… Step 1: Visualize the Problem**\n",
    "\n",
    "Imagine you're trying to predict sales (`y`) based on marketing budget (`x`).  \n",
    "You plot the data points and fit a line using **Linear Regression**.\n",
    "\n",
    "![alt text](images\\Coefficient_of_Determination.svg.png)\n",
    "\n",
    "â¬†ï¸ The curved black line is the mean of y\n",
    "\n",
    "â¬†ï¸ The blue line is your regression model\n",
    "\n",
    "â¬†ï¸ Points are actual values\n",
    "\n",
    "\n",
    "**âœ³ï¸ Components of Variation**\n",
    "\n",
    "There are 3 important terms:\n",
    "\n",
    "| Name                              | Formula                            | Meaning                           |\n",
    "| --------------------------------- | ---------------------------------- | --------------------------------- |\n",
    "| **SST** (Total Sum of Squares)    | $\\sum (y_i - \\bar{y})^2$           | Total variation in y              |\n",
    "| **SSR** (Residual Sum of Squares) | $\\sum (y_i - \\hat{y}_i)^2$         | Error left by the model           |\n",
    "| **SSM** (Model Sum of Squares)    | $\\sum (\\hat{y}_i - \\bar{y})^2$     | Variation explained by the model  |\n",
    "\n",
    "Where:\n",
    "- $y_i$ = actual value  \n",
    "- $\\hat{y}_i$ = predicted value  \n",
    "- $\\bar{y}$ = mean of actual y values\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ“ Graphical Meaning of Each**\n",
    "\n",
    "- **SST** = total vertical distance from each point to the **mean line**  \n",
    "- **SSR** = vertical distance from each point to the **regression line**  \n",
    "- **SSM** = distance from regression line to mean line\n",
    "\n",
    "**Relationship:**\n",
    "\n",
    "$$\n",
    "\\text{SST} = \\text{SSR} + \\text{SSM}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ“ RÂ² Formula**\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\text{SSM}}{\\text{SST}} = 1 - \\frac{\\text{SSR}}{\\text{SST}}\n",
    "$$\n",
    "\n",
    "- Perfect model â†’ SSR = 0 â†’ $R^2 = 1$  \n",
    "- Model as good as mean â†’ SSR = SST â†’ $R^2 = 0$  \n",
    "- Model worse than mean â†’ SSR > SST â†’ $R^2 < 0$\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ’¡ Interpretation**\n",
    "\n",
    "| RÂ² Value | Meaning                                       |\n",
    "| -------- | --------------------------------------------- |\n",
    "| 1        | Perfect model â€” explains 100% of the variance |\n",
    "| 0.9      | Explains 90% of the variation in Y            |\n",
    "| 0.5      | Explains 50% â€” the other 50% is noise         |\n",
    "| 0        | Model no better than mean                     |\n",
    "| < 0      | Model worse than mean (rare!)                 |\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ“Š Example Calculation**\n",
    "\n",
    "Suppose we have:\n",
    "\n",
    "| x | y (actual) | Å· (predicted) |\n",
    "| - | ---------- | ------------- |\n",
    "| 1 | 2          | 2.2           |\n",
    "| 2 | 3          | 2.8           |\n",
    "| 3 | 5          | 5.1           |\n",
    "| 4 | 4          | 4.2           |\n",
    "| 5 | 6          | 5.9           |\n",
    "\n",
    "**Step 1: Mean of y**\n",
    "\n",
    "$$\n",
    "\\bar{y} = \\frac{2 + 3 + 5 + 4 + 6}{5} = 4\n",
    "$$\n",
    "\n",
    "**Step 2: SST (Total variation)**\n",
    "\n",
    "$$\n",
    "(2-4)^2 + (3-4)^2 + (5-4)^2 + (4-4)^2 + (6-4)^2 = 4 + 1 + 1 + 0 + 4 = 10\n",
    "$$\n",
    "\n",
    "**Step 3: SSR (Residual error)**\n",
    "\n",
    "$$\n",
    "(2-2.2)^2 + (3-2.8)^2 + (5-5.1)^2 + (4-4.2)^2 + (6-5.9)^2 = 0.04 + 0.04 + 0.01 + 0.04 + 0.01 = 0.14\n",
    "$$\n",
    "\n",
    "**Step 4: RÂ²**\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{0.14}{10} = 1 - 0.014 = 0.986\n",
    "$$\n",
    "\n",
    "âœ… **98.6% of the variation in y is explained by the model**\n",
    "\n",
    "\n",
    "\n",
    "**âš ï¸ When RÂ² Can Be Misleading**\n",
    "\n",
    "- A high RÂ² doesn't guarantee a good model.\n",
    "    - Model could be **overfitting**\n",
    "    - **Outliers** can inflate RÂ²\n",
    "    - It doesnâ€™t work well for **non-linear relationships**\n",
    "- Always plot residuals and consider **Adjusted RÂ²** in multiple regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121a6bf",
   "metadata": {},
   "source": [
    "<font color = \"Red\">**Adjusted $R^2 - SCORE$**</font>\n",
    "\n",
    "\n",
    "**ğŸš© Why Adjusted RÂ² Came Into Picture**\n",
    "\n",
    "Letâ€™s say you're building a regression model and keep adding more features (predictor variables):\n",
    "\n",
    "| Model | Features Used                               | RÂ² Score |\n",
    "| ----- | ------------------------------------------- | -------- |\n",
    "| A     | `TV Spend`                                  | 0.78     |\n",
    "| B     | `TV + Radio`                                | 0.84     |\n",
    "| C     | `TV + Radio + Mag`                          | 0.88     |\n",
    "| D     | `TV + Radio + Mag + Weather + Day + Region` | 0.91     |\n",
    "\n",
    "ğŸ’¡ **Youâ€™ll notice:**\n",
    "\n",
    "> As we keep adding features, RÂ² **always increases** or stays the same.\n",
    "\n",
    "> Even if the new feature is **completely useless**, RÂ² might still go up a little â€” **thatâ€™s a problem**!\n",
    "\n",
    "\n",
    "\n",
    "**âš ï¸ Problem with RÂ²**\n",
    "\n",
    "RÂ² rewards complexity.\n",
    "\n",
    "But more variables = more chance of **overfitting** â€” fitting to noise rather than true patterns.\n",
    "\n",
    "\n",
    "\n",
    "**âœ… Adjusted RÂ² to the Rescue!**\n",
    "\n",
    "Adjusted RÂ² **penalizes unnecessary variables**.\n",
    "\n",
    "It answers:\n",
    "\n",
    "> â€œIs this new variable really helping the model? Or just making it complex without any real gain?â€\n",
    "\n",
    "**ğŸ’¡ Intuition**\n",
    "\n",
    "| Metric          | Tells You                                                                  |\n",
    "| --------------- | -------------------------------------------------------------------------- |\n",
    "| **RÂ²**          | How much variance your model explains                                      |\n",
    "| **Adjusted RÂ²** | How much *useful* variance is explained, adjusted for number of predictors |\n",
    "\n",
    "So, **Adjusted RÂ² increases only if the new feature actually helps**.\n",
    "If not, it can **decrease**, unlike RÂ² which never goes down.\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ“ Adjusted RÂ² Formula**\n",
    "\n",
    "Let:\n",
    "\n",
    "* `n` = number of data points\n",
    "* `k` = number of independent variables (features)\n",
    "* `RÂ²` = regular RÂ²\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - \\left(1 - R^2\\right) \\cdot \\frac{n - 1}{n - k - 1}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ‘€ What does this formula do?**\n",
    "\n",
    "* It multiplies the unexplained part `(1 - RÂ²)` with a **correction factor**:\n",
    "\n",
    "$$\n",
    "\\frac{n - 1}{n - k - 1}\n",
    "$$\n",
    "\n",
    "* More variables (higher `k`) â†’ higher penalty\n",
    "* Less data (lower `n`) â†’ higher penalty\n",
    "\n",
    "\n",
    "**ğŸ§ª Numerical Example**\n",
    "\n",
    "Suppose:\n",
    "\n",
    "* `n = 30` observations\n",
    "* Model A has `k = 2` features\n",
    "* RÂ² = 0.90\n",
    "\n",
    "Now compute **Adjusted RÂ²**:\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - (1 - 0.9) \\cdot \\frac{29}{27} = 1 - 0.1 \\cdot 1.074 = 0.8926\n",
    "$$\n",
    "\n",
    "\n",
    "**Now suppose you add a **useless feature**:**\n",
    "\n",
    "* `k = 3`, and RÂ² becomes 0.905\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - (1 - 0.905) \\cdot \\frac{29}{26} = 1 - 0.095 \\cdot 1.115 = 0.894\n",
    "$$\n",
    "\n",
    "âœ… So Adjusted RÂ² **barely improved** â†’ small gain.\n",
    "\n",
    "If the new feature was noise, Adjusted RÂ² would go **down**!\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ“‰ What If New Feature Is Useless?**\n",
    "\n",
    "Suppose RÂ² increases just slightly:\n",
    "RÂ² = 0.902\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - (1 - 0.902) \\cdot \\frac{29}{26} = 1 - 0.098 \\cdot 1.115 = 0.891\n",
    "$$\n",
    "\n",
    "ğŸ˜Ÿ It actually **went down** from 0.8926 â†’ 0.891\n",
    "ğŸ‘‰ This feature made your model *worse*, even though RÂ² increased.\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ” Use Case in Real Life**\n",
    "\n",
    "When youâ€™re comparing **multiple regression models** with different numbers of features:\n",
    "\n",
    "| Model       | Features Used                      | RÂ²   | Adjusted RÂ² |\n",
    "| ----------- | ---------------------------------- | ---- | ----------- |\n",
    "| Basic       | `TV`                               | 0.76 | 0.755       |\n",
    "| Improved    | `TV + Radio`                       | 0.84 | 0.832       |\n",
    "| Too Complex | `TV + Radio + Region + Day + Temp` | 0.87 | 0.843 âœ…     |\n",
    "\n",
    "The third model looks good in RÂ² but Adjusted RÂ² tells you itâ€™s **barely better than 2-feature model**.\n",
    "\n",
    "\n",
    "**ğŸ“Š Graphical Intuition**\n",
    "\n",
    "If you want to picture it like a curve:\n",
    "\n",
    "* RÂ² will keep increasing or flatten\n",
    "* Adjusted RÂ² increases then **starts to decrease** when features are just noise\n",
    "\n",
    "```\n",
    "Adjusted RÂ²\n",
    "   â–²\n",
    "1  |          ____\n",
    "   |         /\n",
    "   |   _____/\n",
    "   |\n",
    "   +--------------------â–¶ Number of Features\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ§  Summary Table**\n",
    "\n",
    "| Term        | Meaning                                                  |\n",
    "| ----------- | -------------------------------------------------------- |\n",
    "| RÂ²          | Total variance explained by model                        |\n",
    "| Adjusted RÂ² | True explanatory power **adjusted for model complexity** |\n",
    "| Penalty     | Based on number of features & sample size                |\n",
    "| Use Case    | Best for comparing **multiple regression** models        |\n",
    "\n",
    "\n",
    "\n",
    "**âœ… When to Use Adjusted RÂ²**\n",
    "\n",
    "| Scenario                                 | Use Adjusted RÂ²? |\n",
    "| ---------------------------------------- | ---------------- |\n",
    "| Simple Linear Regression (1 variable)    | âŒ Not needed     |\n",
    "| Multiple Linear Regression               | âœ… YES            |\n",
    "| Comparing models with different features | âœ… YES            |\n",
    "| Feature selection during model tuning    | âœ… YES            |\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ‘¨â€ğŸ« Final Advice**\n",
    "\n",
    "* RÂ² is useful, but donâ€™t trust it blindly\n",
    "* When building models with more than 1 feature, **always check Adjusted RÂ²**\n",
    "* It acts like a **truth detector** â€” filtering out \"fake gains\" in RÂ²\n",
    "* Pair Adjusted RÂ² with **Cross-validation**, **RMSE**, and **MAE** for serious modeling\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
